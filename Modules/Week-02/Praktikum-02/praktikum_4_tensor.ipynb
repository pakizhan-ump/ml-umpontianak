{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f9a9170",
   "metadata": {},
   "source": [
    "# Praktikum 4: Pengenalan Tensor pada PyTorch\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/pakizhan-ump/ml-umpontianak/blob/main/Modules/Week-02/Praktikum-02/Praktikum_3_tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## ðŸŽ¯ Tujuan Praktikum\n",
    "Mahasiswa memahami struktur data dasar dalam library **PyTorch**, yaitu **Tensor**, dan mampu melakukan operasi-operasi fundamental yang menjadi dasar dari komputasi deep learning.\n",
    "\n",
    "## ðŸ“– Dasar Teori\n",
    "**PyTorch** adalah salah satu *framework* deep learning terpopuler. Unit data fundamental di PyTorch adalah **Tensor**. Secara konseptual, sebuah tensor adalah generalisasi dari vektor dan matriks ke dimensi yang lebih tinggi.\n",
    "* Skalar = Tensor 0D\n",
    "* Vektor = Tensor 1D\n",
    "* Matriks = Tensor 2D\n",
    "\n",
    "Tensor sangat mirip dengan NumPy ndarray, namun memiliki dua keunggulan krusial untuk deep learning:\n",
    "1.  **Akselerasi GPU:** Tensor dapat dengan mudah dipindahkan ke *Graphics Processing Unit* (GPU) untuk mendapatkan percepatan komputasi yang masif. Ini sangat penting untuk melatih model deep learning yang kompleks pada data besar.\n",
    "2.  **Dukungan Autograd:** PyTorch dapat secara otomatis melacak histori operasi pada tensor dan menghitung gradien (turunan) dari operasi tersebut. Fitur ini, yang disebut *automatic differentiation*, adalah inti dari algoritma *backpropagation* yang digunakan untuk melatih hampir semua jaringan saraf tiruan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e6d78a",
   "metadata": {},
   "source": [
    "# ðŸ”§ OPERASI FUNDAMENTAL PYTORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f9628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450749ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a5029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d9085c",
   "metadata": {},
   "source": [
    "# 1. TENSOR CREATION & TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f7e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== TENSOR CREATION ===\")\n",
    "# Various creation methods\n",
    "tensor_zeros = torch.zeros(2, 3)                    # Zeros tensor\n",
    "tensor_ones = torch.ones(2, 3)                      # Ones tensor  \n",
    "tensor_rand = torch.rand(2, 3)                      # Random [0,1)\n",
    "tensor_randn = torch.randn(2, 3)                    # Normal distribution\n",
    "tensor_arange = torch.arange(0, 10, 2)              # Like range()\n",
    "\n",
    "print(\"Zeros tensor:\\n\", tensor_zeros)\n",
    "print(\"Random tensor:\\n\", tensor_rand)\n",
    "print(\"Arange tensor:\", tensor_arange)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323fa6d4",
   "metadata": {},
   "source": [
    "# 2. DATA TYPES & SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58aa0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== DATA TYPES & SHAPE ===\")\n",
    "tensor_int = torch.tensor([1, 2, 3], dtype=torch.int32)\n",
    "tensor_float = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "\n",
    "print(\"Integer tensor dtype:\", tensor_int.dtype)\n",
    "print(\"Float tensor dtype:\", tensor_float.dtype)\n",
    "print(\"Tensor shape:\", tensor_float.shape)\n",
    "print(\"Tensor size:\", tensor_float.size())\n",
    "print(\"Number of elements:\", tensor_float.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d872a",
   "metadata": {},
   "source": [
    "# 3. ACCESS & SLICING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38400ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== ACCESS & SLICING ===\")\n",
    "tensor_2d = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"Original tensor:\\n\", tensor_2d)\n",
    "print(\"Element [1,2]:\", tensor_2d[1, 2])\n",
    "print(\"First row:\", tensor_2d[0, :])\n",
    "print(\"Last column:\", tensor_2d[:, -1])\n",
    "print(\"Submatrix:\\n\", tensor_2d[0:2, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed427bea",
   "metadata": {},
   "source": [
    "# 4. RESHAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df00a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== RESHAPING ===\")\n",
    "tensor_1d = torch.arange(12)\n",
    "print(\"Original shape:\", tensor_1d.shape)\n",
    "\n",
    "reshaped = tensor_1d.reshape(3, 4)                  # Reshape\n",
    "viewed = tensor_1d.view(3, 4)                       # View (shares memory)\n",
    "transposed = reshaped.T                             # Transpose\n",
    "flattened = reshaped.flatten()                      # Flatten\n",
    "\n",
    "print(\"Reshaped 3x4:\\n\", reshaped)\n",
    "print(\"Transposed 4x3:\\n\", transposed)\n",
    "print(\"Flattened:\", flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f24385",
   "metadata": {},
   "source": [
    "# 5. MATHEMATICAL OPERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== MATHEMATICAL OPERATIONS ===\")\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "print(\"a + b =\", a + b)                             # Element-wise\n",
    "print(\"a * b =\", a * b)\n",
    "print(\"a ** 2 =\", a ** 2)\n",
    "print(\"torch.matmul:\", torch.matmul(a, b))          # Dot product\n",
    "print(\"torch.sum(a) =\", torch.sum(a))               # Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d91679",
   "metadata": {},
   "source": [
    "# 6. AGGREGATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbed82c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== AGGREGATION ===\")\n",
    "data = torch.randn(4, 5)                            # Random data\n",
    "print(\"Data tensor:\\n\", data)\n",
    "print(\"Global sum:\", torch.sum(data))\n",
    "print(\"Mean along dim 0:\", torch.mean(data, dim=0)) # Column means\n",
    "print(\"Max along dim 1:\", torch.max(data, dim=1))   # Row maximums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea4afc",
   "metadata": {},
   "source": [
    "# 7. BROADCASTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d02b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== BROADCASTING ===\")\n",
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "vector = torch.tensor([10, 20, 30])\n",
    "\n",
    "result = matrix + vector                            # Broadcasting\n",
    "print(\"Matrix:\\n\", matrix)\n",
    "print(\"Vector:\", vector)\n",
    "print(\"Broadcast result:\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f36b977",
   "metadata": {},
   "source": [
    "# 8. RANDOM OPERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114efba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== RANDOM OPERATIONS ===\")\n",
    "torch.manual_seed(42)                               # Set seed\n",
    "random_tensor = torch.rand(2, 3)                    # Uniform\n",
    "normal_tensor = torch.randn(2, 3)                   # Normal\n",
    "randint_tensor = torch.randint(0, 10, (2, 3))       # Integers\n",
    "\n",
    "print(\"Uniform random:\\n\", random_tensor)\n",
    "print(\"Normal random:\\n\", normal_tensor)\n",
    "print(\"Random integers:\\n\", randint_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8da42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. CONCATENATION & SPLITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bfc17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== CONCATENATION & SPLITTING ===\")\n",
    "t1 = torch.tensor([[1, 2], [3, 4]])\n",
    "t2 = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "# Concatenation\n",
    "cat_vertical = torch.cat([t1, t2], dim=0)           # Vertical\n",
    "cat_horizontal = torch.cat([t1, t2], dim=1)         # Horizontal\n",
    "\n",
    "print(\"Vertical concat:\\n\", cat_vertical)\n",
    "print(\"Horizontal concat:\\n\", cat_horizontal)\n",
    "\n",
    "# Splitting\n",
    "chunks = torch.chunk(cat_vertical, 2, dim=0)        # Split into chunks\n",
    "print(\"After splitting:\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i}:\\n{chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297dad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. GPU OPERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b3b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== GPU OPERATIONS ===\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    tensor_gpu = tensor_2d.to(device)               # Move to GPU\n",
    "    print(f\"Tensor on: {tensor_gpu.device}\")\n",
    "    \n",
    "    # Operations on GPU\n",
    "    result_gpu = tensor_gpu + 1\n",
    "    print(\"GPU operation result on CPU:\", result_gpu.cpu())\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e1f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ‹ï¸ LATIHAN 4: OPERASI PYTORCH UNTUK DEEP LEARNING\n",
    "\n",
    "### TENSOR OPERATIONS FOR NEURAL NETWORKS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ddec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''TODO: Implementasi Operasi Dasar Neural Networks'''\n",
    "# Simulasi batch data: 32 samples, 10 features\n",
    "batch_size, n_features = 32, 10\n",
    "X = torch.randn(batch_size, n_features)\n",
    "weights = torch.randn(n_features, 1)\n",
    "bias = torch.randn(1)\n",
    "\n",
    "# TODO 1: Implementasi linear layer manual: y = XW + b\n",
    "def linear_layer(X, W, b):\n",
    "    # TODO: Implementasi operasi linear\n",
    "    pass\n",
    "\n",
    "output = linear_layer(X, weights, bias)\n",
    "\n",
    "# TODO 2: Implementasi ReLU activation function\n",
    "def relu_activation(tensor):\n",
    "    # TODO: Implementasi ReLU: max(0, x)\n",
    "    pass\n",
    "\n",
    "activated = relu_activation(output)\n",
    "\n",
    "# TODO 3: Batch normalization sederhana\n",
    "def simple_batch_norm(tensor):\n",
    "    # TODO: Normalisasi per feature across batch\n",
    "    # Formula: (x - mean) / (std + epsilon)\n",
    "    pass\n",
    "\n",
    "normalized = simple_batch_norm(X)\n",
    "\n",
    "# TODO 4: One-hot encoding manual\n",
    "def one_hot_pytorch(labels, num_classes):\n",
    "    # TODO: Convert labels to one-hot encoding\n",
    "    pass\n",
    "\n",
    "labels = torch.randint(0, 3, (10,))\n",
    "one_hot = one_hot_pytorch(labels, num_classes=3)\n",
    "\n",
    "assert output.shape == (batch_size, 1), \"Linear output shape incorrect\"\n",
    "assert torch.all(activated >= 0), \"ReLU should be >= 0\"\n",
    "assert normalized.shape == X.shape, \"Batch norm should preserve shape\"\n",
    "assert one_hot.shape == (10, 3), \"One-hot shape incorrect\"\n",
    "print(\"âœ… PyTorch operations completed\")\n",
    "\n",
    "### BONUS: ADVANCED TENSOR OPERATIONS ###\n",
    "\n",
    "'''TODO: Matrix Multiplication dari Prinsip Dasar'''\n",
    "def manual_matrix_multiply(A, B):\n",
    "    \"\"\"\n",
    "    Implementasi perkalian matriks manual tanpa torch.matmul\n",
    "    \"\"\"\n",
    "    # TODO: Implementasi perkalian matriks dari dasar\n",
    "    # Hint: Gunakan nested loops atau broadcasting\n",
    "    pass\n",
    "\n",
    "# Test dengan matriks kecil\n",
    "A = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "B = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
    "\n",
    "manual_result = manual_matrix_multiply(A, B)\n",
    "torch_result = torch.matmul(A, B)\n",
    "\n",
    "assert torch.allclose(manual_result, torch_result), \"Manual multiplication incorrect\"\n",
    "print(\"âœ… Advanced tensor operations completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
